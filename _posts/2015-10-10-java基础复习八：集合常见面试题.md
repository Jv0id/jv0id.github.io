---

title: "java基础复习八：集合常见面试题"
key: java基础
tags: java基础 集合
author: jv0id
---



### HashMap和ConcurrentHashMap的区别

- **Hashmap**本质是数组加链表。根据key取得hash值，然后计算出数组下标，如果多个key对应到同一个下标，就把数据用链表串起来，新插入的在前面，然后放到key对应的下标位置。
- **多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。**
- **ConcurrentHashMap**：在hashMap的基础上，ConcurrentHashMap将数据分为多个segment(段)，默认16个（concurrency level），然后每次操作对一个segment(段)加锁，避免多线程锁的几率，提高并发效率，他是**线程安全的**。



#### HashMap

- HashMap基于哈希表的 `Map` 接口的实现。
- 此实现提供所有可选的映射操作，并允许使用 `null` 值和 `null` 键。
- 此类不保证映射的顺序，特别是它不保证该顺序恒久不变。
- HashMap不是线程安全的，如果想要线程安全的HashMap，可以通过Collections类的静态方法synchronizedMap获得线程安全的HashMap。` Map map = Collections.synchronizedMap(new HashMap());`
- HashMap中主要是通过key的hashCode来计算hash值的，只要hashCode相同，计算出来的hash值就一样。
- 如果存储的对象对多了，就有可能不同的对象所算出来的hash值是相同的，这就出现了所谓的hash冲突。
- 解决hash冲突的方法有很多，**HashMap底层是通过链表来解决hash冲突的。**

```
JDK1.7是使用链表来解决哈希冲突
0 []-->[]
1 []
2 [第三次存储]-->[第二次存储]-->[第一次存储]
3 []
```

- 从上图中可以看出，HashMap底层就是一个数组结构，数组中存放的是一个Entry对象，如果产生hash冲突，也就是说要存储的那个位置上面已经存储了对象了，这时候该位置存储的就是一个链表了。

```java
static class Entry<K,V> implements Map.Entry<K,V> {
        final K key;
        V value;
        Entry<K,V> next;
        final int hash;

        /**
         * Creates new entry.
         */
        Entry(int h, K k, V v, Entry<K,V> n) {
            value = v;
            next = n; //hash值冲突后存放在链表的下一个
            key = k;
            hash = h;
        }
     //   .........
    }
```

- HashMap其实就是一个Entry数组，Entry对象中包含了键和值，其中next也是一个Entry对象，它就是用来处理hash冲突的，形成一个链表。

```java
//HashMap类中的一些关键属性
transient Entry[] table;//存储元素的实体数组

transient int size;//存放元素的个数

int threshold; //临界值   当实际大小超过临界值时，会进行扩容threshold = 加载因子*容量

final float loadFactor; //加载因子
/*
其中加载因子是表示Hash表中元素的填满的程度.若:加载因子越大,填满的元素越多,好处是,空间利用率高了,但:冲突的机会加大了.反之,加载因子越小,填满的元素越少,好处是:冲突的机会减小了,但:空间浪费多了.冲突的机会越大,则查找的成本越高.反之,查找的成本越小.因而,查找时间就越小
必须在 "冲突的机会"与"空间利用率"之间寻找一种平衡与折衷
如果机器内存足够，并且想要提高查询速度的话可以将加载因子设置小一点；相反如果机器内存紧张，并且对查询速度没有什么要求的话可以将加载因子设置大一点。不过一般我们都不用去设置它，让它取默认值0.75就好了。
*/

transient int modCount;//被修改的次数
```

- HashMap存储数据的过程:

```java
public V put(K key, V value) {
        if (key == null) //如果键为null的话，调用putForNullKey(value)
            return putForNullKey(value);
        int hash = hash(key.hashCode());//根据键的hashCode计算hash码
        int i = indexFor(hash, table.length);//使用&运算计算数组下标（hash & table.length-1）
        for (Entry<K,V> e = table[i]; e != null; e = e.next) { //处理冲突的，如果hash值相同，则在该位置用链表存储
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) { //如果key相同则覆盖并返回旧值
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }

        modCount++;
        addEntry(hash, key, value, i);
        return null;
    }
```

- 当我们往hashmap中put元素的时候，先根据key的hash值得到这个元素在数组中的位置（即下标），然后就可以把这个元素放到对应的位置中了。
- 如果这个元素所在的位子上已经存放有其他元素了，那么在同一个位子上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。
- 从hashmap中get元素时，首先计算key的hashcode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元素。
- 当你的key为null时，会调用**putForNullKey,HashMap允许key为null,这样的对像是放在table[0]中。**
- 如果不为空，则调用int hash = hash(key.hashCode());这是hashmap的一个自定义的hash,在key.hashCode()基础上进行二次hash

```java
 static int hash(int h) {  
         h ^= (h >>> 20) ^ (h >>> 12);  
         return h ^ (h >>> 7) ^ (h >>> 4);  
   }
```

- 得到hash码之后就会通过hash码去计算出应该存储在数组中的索引，计算索引的函数如下：

```java
 static int indexFor(int h, int length) {  
        return h & (length-1);  
    }
/*
它通过 h & (table.length -1) 来得到该对象的保存位，而HashMap底层数组的长度总是 2 的n 次方，这是HashMap在速度上的优化。
当length总是 2 的n次方时，h& (length-1)运算等价于对length取模，也就是h%length，但是&比%具有更高的效率。
当数组长度为2的n次幂的时候，不同的key算得的index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。
*/
```

- 如果数组中该索引的位置的链表已经存在key相同的对象，则将其覆盖掉并返回原先的值。如果没有与key相同的键，则调用addEntry方法创建一个Entry对象

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
        Entry<K,V> e = table[bucketIndex]; //如果要加入的位置有值，将该位置原先的值设置为新entry的next,也就是新entry链表的下一个节点
        table[bucketIndex] = new Entry<>(hash, key, value, e);
        if (size++ >= threshold) //如果大于临界值就扩容
            resize(2 * table.length); //以2的倍数扩容
    }
```

- 参数bucketIndex就是indexFor函数计算出来的索引值，第2行代码是取得数组中索引为bucketIndex的Entry对象，第3行就是用hash、key、value构建一个新的Entry对象放到索引为bucketIndex的位置，并且将该位置原先的对象设置为新对象的next构成链表。
- 第4行和第5行就是判断put后size是否达到了临界值threshold，如果达到了临界值就要进行扩容，HashMap扩容是扩为原来的两倍

```java
void resize(int newCapacity) {
        Entry[] oldTable = table;
        int oldCapacity = oldTable.length;
        if (oldCapacity == MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return;
        }

        Entry[] newTable = new Entry[newCapacity];
        transfer(newTable);//用来将原先table的元素全部移到newTable里面
        table = newTable;  //再将newTable赋值给table
        threshold = (int)(newCapacity * loadFactor);//重新计算临界值
    }
```

[原文](https://www.cnblogs.com/shan1393/p/8999458.html)

#### ConcurrentHashMap

- 1.7是在jdk1.7中采用Segment + HashEntry的方式进行实现的，lock加在Segment上面。1.7size计算是先采用不加锁的方式，连续计算元素的个数，最多计算3次：1、如果前后两次计算结果相同，则说明计算出来的元素个数是准确的；2、如果前后两次计算结果都不同，则给每个Segment进行加锁，再计算一次元素的个数；
- 1.8中放弃了Segment臃肿的设计，取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现，1.8中使用一个volatile类型的变量baseCount记录元素的个数，当插入新数据或则删除数据时，会通过addCount()方法更新baseCount，通过累加baseCount和CounterCell数组中的数量，即可得到元素的总个数；

- HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。
- 因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。
- 如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。


- **锁分段技术**
- HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率
- **这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储**，**然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问**。
- **有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。**
- **这里“按顺序”是很重要的，否则极有可能出现死锁**，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。


- **ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成**
- Segment是一种**可重入锁ReentrantLock**，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。
- 一个ConcurrentHashMap**里包含一个Segment数组**，**Segment的结构和HashMap类似，是一种数组和链表结构**， **一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护着一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。**

![](https://images2017.cnblogs.com/blog/400827/201709/400827-20170928212457434-1134706220.png)

[原文](https://www.cnblogs.com/shan1393/p/9020564.html)


### TreeMap底层红黑树原理

- TreeMap 的实现就是红黑树数据结构，也就说是一棵自平衡的排序二叉树，这样就可以保证当需要快速检索指定节点。
- 红黑树的插入、删除、遍历时间复杂度都为O(lgN)，所以性能上低于哈希表。但是哈希表无法提供键值对的有序输出，红黑树因为是排序插入的，可以按照键的值的大小有序输出。
- TreeMap实现SortMap接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当使用Iterator遍历TreeMap时，得到的记录是排过序的

[原文](https://blog.csdn.net/chenssy/article/details/26668941)

[红黑树](https://blog.csdn.net/qq_36925536/article/details/87624130)


### 迭代器

#### 什么是迭代器

- Iterator提供了统一遍历操作集合元素的统一接口, Collection接口实现Iterable接口
- 每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例, 然后对集合的元素进行迭代操作
- 在迭代元素的时候不能通过集合的方法删除元素, 否则会抛出ConcurrentModificationException 异常. 但是可以通过Iterator接口中的remove()方法进行删除


#### iterator和ListIterator区别

- Iterator可用来遍历Set和List集合，但是ListIterator只能用来遍历List。
- terator对集合只能是前向遍历，ListIterator既可以前向也可以后向
- ListIterator实现了Iterator接口，并包含其他的功能，比如：增加元素，替换元素，获取前一个和后一个元素的索引，等等。

#### 快速失败和安全失败的区别

- Iterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。
- java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。
- 快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常


### ArrayList,Vector,LinkedList的存储性能和特性是什么？

- ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢
- Vector由于使用了synchronized方法（线程安全），通常性能上较ArrayList差
- 而LinkedList使用双向链表实现存储，按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。


### Collection 和 Collections的区别

- Collection是集合类的上级接口，继承与他的接口主要有Set 和List
- Collections是针对集合类的一个帮助类，他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作
