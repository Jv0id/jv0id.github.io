---
title: "linux命令集笔记"
layout: post
date: 2019-09-05 12:08
headerImage: false
tag:
- centos
- 命令
- linux
category: blog
author: 夏潇熙
description: linux命令集笔记
---


##### git lfs:
`git lfs clone -b ezsonar3.x http://192.168.1.141:10080/ops/ez-component.git`     
##### yum下载downloadonly插件



```bash
yum install yum-plugin-downloadonly
yum install --downloadonly --downloaddir=/tmp <package-name>
#### 创建yum repo本地索引文件
yum -y install createrepo
createrepo -pdo /dir/local_yum_dir/ /dir/local_yum_dir/
createrepo -upmodify_date /dir/local_yum_dir/
```

#####  获取ip地址
```bash
ifconfig | grep inet | awk 'NR==1{print $2}'| awk -F: '{print $2}'|awk -F. '{print $2}'
```
> NR==1 代表第一行 awk -F: 以冒号分割

##### 查看当前目录下各个文件及目录占用空间大小
```bash
du -sh *
```

##### 更新Linux网络时间
```bash
yum -y install ntpmodify_date
ntpmodify_date time.windows.com
```

##### 修改linux系统的时间EDT和EST为CST
```bash
mv /etc/localtime /etc/localtime.bak
ln -s /usr/share/zoneinfo/Asia/Shanghai  /etc/localtime
```

##### kafka启动、生产者、消费者
```bash
nohup bin/kafka-server-start.sh config/server.properties &
bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092 --topic test
bin/kafka-console-consumer.sh  --bootstrap-server 127.0.0.1:9092 --topic test --from-beginning
```

##### Kafka设置日志输出路径 
`LOG_DIR在$KAFKA_HOME/bin/kafka-run-class.sh中的LOG_DIR=`
##### 查看topic
`bin/kafka-topics.sh --list --zookeeper localhost:2181`
##### 创建topic
`bin/kafka-topics.sh --create --topic topicname --replication-factor 1 --partitions 1 --zookeeper localhost:2181` 
##### 删除topic
`bin/kafka-topics.sh --delete --topic topicname --zookeeper localhost:2181` 

##### 启动filebeat
```bash
nohup ./filebeat -c filebeat.yml &
```
##### 配置filebeat.yml的kafka
1，删除ES的相关配置      
2，添加kafka的配置
```yaml
#================================ Outputs =====================================
output.kafka:
  enabled: true
  hosts: ["111.11.1.243:9092"]
  topic: test
```
##### elasticsearch启动
###### 切换用户elasticsearch
`su - elasticsearch`          
`./elasticsearch -d`

##### flume启动
```bash
./flume-ng agent --conf ../conf --conf-file ../conf/flume.conf --name a1 -Dflume.monitoring.type=http -Dflume.monitoring.port=5656 -Dflume.root.logger=INFO,console
```

##### shell中多个数组组成一个新的大数组
两种方式：
>1、array_new=(${array1[@]}  ${array2[@]})    
>2、array_new=(${array1[*]}  ${array2[*]})

##### 重定向到空
* `cat $badname 2>/dev/null`：输出标准日志。      
* `cat $badname 1>/dev/null` 或`cat $badname >/dev/null` ：输出标准错误。       
* `cat $badname &>/dev/null` ：正确或错误信息都不输出。 一般写作：`>/dev/null 2>&1` ，效率更高      
- `>/dev/null 2>&1`：标准输出和标准错误都重定向到了/dev/null
- `2>&1 >/dev/null`：标准错误打印到屏幕，而标准输出不打印到屏幕

> 详细解释：       
> `>/dev/null 2>&1`         
  实际上，应该等同于这样： 1>/dev/null 2>/dev/null ，默认情况下就是1，标准输出，所以一般都省略。 而&符号，后面接的是必须的文件描述符。不能写成2>1，这样就成了标准错误重定向到文件名为1的文件中了，而不是重定向标准错误到标准输出中。所以这里就是：标准输出重定向到了/dev/null，而标准错误又重定向到了标准输出，所以就成了标准输出和标准错误都重定向到了/dev/null

> `2>&1 >/dev/null`          
  咋一看，这个跟上面那个有啥区别呢，不也是标准错误重定向到标准输出，而标准输出重定向到/dev/null么？ 最后不应该都重定向/dev/null么？ 我是这么理解的！一条指令同一时刻要么产生标准错误，要么产生标准输出。 当产出标准错误的时候，因这个标准错误重定向到了标准输出，而标准输出是输出到屏幕。这个时候标准输出还没有被重定向到/dev/null，于是在屏幕上打印了。当产生标准输出时，那么它就不是标准错误，2>&1无效，于是标准输出重定向dev/null，不打印到屏幕。所以最终结果将是：标准错误打印到屏幕，而标准输出不打印到屏幕。

##### zabbix获取item信息
```bash
zabbix_get -s 192.168.22.166 -p 10050 -k "error_log"
```

##### es删除所有索引
```bash
curl -XDELETE 'http://localhost:9200/_all'
```

##### VUE编译
```bash
npm install      
npm run build

#页面启动
npm run dev      
```

##### mac查看端口
`lsof -i:8084`

##### 去除Linux的 “You have mail in /var/spool/mail/root”
```bash
echo "unset MAILCHECK">> /etc/profile
source /etc/profile 
```

##### Docker列出容器
`docker ps` (-a:显示所有的容器，包括未运行的。)
###### 进入容器：
`sudo docker exec -it 容器ID  /bin/bash`

##### awk split分割字符串
`echo ‘abcd’ | awk ‘{len=split($0,a,””);for(i=1;i<=len;i++)print “a[“i”]=”a[i];print “length=”len}’`
```
a[1]=a
a[2]=b
a[3]=c
a[4]=d
length=4
```
> 解析说明：首先把abcd换为一个数组，并且数组的分隔符为没有符号，len=split($0,a,””)为获取了整个数组的长度，之后进行输出。在awk中如果是当做字符串输出的字符，全部用双引号来引起来。
awk sub和gsub区别及用法
sub匹配第一次出现的符合模式的字符串，相当于 sed 's//'   。
gsub匹配所有的符合模式的字符串，相当于 sed 's//g'   。
例如：
awk '{sub(/Mac/,"Macintosh");print}' urfile    用Macintosh替换Mac
awk '{sub(/Mac/,"MacIntosh",$1); print}' file    第一个域内用Macintosh替换Mac

##### Linux lsattr命令用于显示文件属性。
##### 用chattr执行改变文件或目录的属性，可执行lsattr指令查询其属性。
`lsattr [-adlRvV][文件或目录...]`
##### 用chattr命令防止系统中某个关键文件被修改：
`chattr +i /etc/resolv.conf`
>然后用mv /etc/resolv.conf等命令操作于该文件，都是得到Operation not permitted 的结果。
vim编辑该文件时会提示W10: Warning: Changing a readonly file错误。要想修改此文件就要把i属性去掉：
chattr -i /etc/resolv.conf

>使用 lsattr 命令来显示文件属性：
`lsattr /etc/resolv.conf`
输出结果为:
`----i-------- /etc/resolv.conf`

> 让某个文件只能往里面追加数据，但不能删除，适用于各种日志文件：
`chattr +a /var/log/messages`     
a：让文件或目录仅供附加用途；         
b：不更新文件或目录的最后存取时间；          
c：将文件或目录压缩后存放；            
d：将文件或目录排除在倾倒操作之外；              
i：不得任意更动文件或目录；              
s：保密性删除文件或目录；             
S：即时更新文件或目录；            
u：预防意外删除。             

##### 获取外网命令：
`curl -L tool.lu/ip`

##### shell脚本中 read -e参数的正确解读
Read可以带有-a, -d, -e, -n, -p, -r, -t等等选项。           
网上对其它解释都较为详细，偏偏对-e模糊不祥。             
这里只对-e参数作出解释，其它请自行查询。             
随便在Linux终端上敲入read命令，如下:             
`root$ read`           
`test^H^H^H^[[A^[[B^[[D^[[C^[OP^[OQ^[OR^[OS` 注：我输入的分别是test、backspace键、上下左右、F1F2F3F4           
你可以看到这些功能键变成了原来的字符组合，并且功能键的功能失效了！                
下面进行read -e的输入：              
`root$ read -e`             
`test`             
现在所有输入都已恢复正常！             
总结：`read -e`参数的功能就是在获取用户输入的时候，对功能键做了处理，不会直接出现直接显示字符这个问题！这其实是一种编码转换的问题。          
